{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIDefzXs8cQlQkja9sYtiy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizsolano/Optativa_profesionalizante_I/blob/main/NYHouseDatabase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "rv2Wfbk303Db"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos la bd\n",
        "\n",
        "#data = pd.read_csv(\"C:/Users/Lizeth Solano Romo/OneDrive - Universidad Autónoma de Aguascalientes/2024/MATERIAS/agosto-diciembre/LITC/7o/Ejercicios Phyton/NY-House-Dataset.csv\")\n",
        "data = pd.read_csv(r\"C:\\Users\\lizet\\OneDrive - Universidad Autónoma de Aguascalientes\\2024\\MATERIAS\\agosto-diciembre\\LITC\\7o\\Ejercicios Phyton\\NY-House-Dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "2_EmtFWa1IJF",
        "outputId": "34e06f2f-fa74-4b5c-83dc-20c7f0f2192c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\lizet\\\\OneDrive - Universidad Autónoma de Aguascalientes\\\\2024\\\\MATERIAS\\\\agosto-diciembre\\\\LITC\\\\7o\\\\Ejercicios Phyton\\\\NY-House-Dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6605f91631d2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#data = pd.read_csv(\"C:/Users/Lizeth Solano Romo/OneDrive - Universidad Autónoma de Aguascalientes/2024/MATERIAS/agosto-diciembre/LITC/7o/Ejercicios Phyton/NY-House-Dataset.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"C:\\Users\\lizet\\OneDrive - Universidad Autónoma de Aguascalientes\\2024\\MATERIAS\\agosto-diciembre\\LITC\\7o\\Ejercicios Phyton\\NY-House-Dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\lizet\\\\OneDrive - Universidad Autónoma de Aguascalientes\\\\2024\\\\MATERIAS\\\\agosto-diciembre\\\\LITC\\\\7o\\\\Ejercicios Phyton\\\\NY-House-Dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf6OfARD01Tf"
      },
      "outputs": [],
      "source": [
        "#Cargamos la bd\n",
        "\n",
        "data = pd.read_csv(\"C:/Users/Lizeth Solano Romo/OneDrive - Universidad Autónoma de Aguascalientes/2023/diplomado unam/Modulo III/practicas/NY-House-Dataset.csv\")\n",
        "\n",
        "# Realizamos el analisis exploratorio que se realizó en R:\n",
        "#Conteo de categorias\n",
        "print(data[\"BROKERTITLE\"].value_counts())\n",
        "print(data[\"TYPE\"].value_counts())\n",
        "print(data[\"STATE\"].value_counts())\n",
        "print(data[\"LOCALITY\"].value_counts())\n",
        "print(data[\"SUBLOCALITY\"].value_counts())\n",
        "\n",
        "#descripcion de variables numericas:\n",
        "print(data[[\"PRICE\",\"BEDS\",\"BATH\",\"PROPERTYSQFT\"]].describe())\n",
        "\n",
        "#transformar categorias con menos de 10 registros a una nueva:\n",
        "#BROKERTITLE\n",
        "BROKERTITLE_conteo = data[\"BROKERTITLE\"].value_counts()\n",
        "BROKERTITLE_conservar = BROKERTITLE_conteo[BROKERTITLE_conteo>=10].index.to_list()\n",
        "data[\"BROKERTITLE\"]=np.where(data[\"BROKERTITLE\"].isin(BROKERTITLE_conservar),data[\"BROKERTITLE\"],\"No se especifica\")\n",
        "\n",
        "#TYPE\n",
        "TYPE_conteo = data[\"TYPE\"].value_counts()\n",
        "TYPE_conservar = TYPE_conteo[TYPE_conteo>=10].index.to_list()\n",
        "data[\"TYPE\"]=np.where(data[\"TYPE\"].isin(TYPE_conservar),data[\"TYPE\"],\"No se especifica\")\n",
        "\n",
        "#STATE Y CP\n",
        "data[\"STATE_2\"]=data[\"STATE\"].str.extract(\"^([^,]+)\")\n",
        "data[\"codigo_postal\"]=data[\"STATE\"].str.extractall(\"(\\d+)\").groupby(level=0).apply(lambda x: x.iloc[-1])\n",
        "\n",
        "#STATE_2\n",
        "STATE_2_conteo = data[\"STATE_2\"].value_counts()\n",
        "STATE_2_conservar = STATE_2_conteo[STATE_2_conteo>=10].index.to_list()\n",
        "data[\"STATE_2\"]=np.where(data[\"STATE_2\"].isin(STATE_2_conservar),data[\"STATE_2\"],\"No se especifica\")\n",
        "\n",
        "#codigo_postal\n",
        "codigo_postal_conteo = data[\"codigo_postal\"].value_counts()\n",
        "codigo_postal_conservar = codigo_postal_conteo[codigo_postal_conteo>=10].index.to_list()\n",
        "data[\"codigo_postal\"]=np.where(data[\"codigo_postal\"].isin(codigo_postal_conservar),data[\"codigo_postal\"],\"No se especifica\")\n",
        "\n",
        "#LOCALITY\n",
        "LOCALITY_conteo = data[\"LOCALITY\"].value_counts()\n",
        "LOCALITY_conservar = LOCALITY_conteo[LOCALITY_conteo>=10].index.to_list()\n",
        "data[\"LOCALITY\"]=np.where(data[\"LOCALITY\"].isin(LOCALITY_conservar),data[\"LOCALITY\"],\"No se especifica\")\n",
        "\n",
        "\n",
        "#SUBLOCALITY\n",
        "SUBLOCALITY_conteo = data[\"SUBLOCALITY\"].value_counts()\n",
        "SUBLOCALITY_conservar = SUBLOCALITY_conteo[SUBLOCALITY_conteo>=10].index.to_list()\n",
        "data[\"SUBLOCALITY\"]=np.where(data[\"SUBLOCALITY\"].isin(SUBLOCALITY_conservar),data[\"SUBLOCALITY\"],\"No se especifica\")\n",
        "\n",
        "#TABLA DESCRIPTIVA:\n",
        "Tabla_Descriptiva_Final = data.groupby(['TYPE','STATE_2','codigo_postal','LOCALITY','SUBLOCALITY']).agg(\n",
        "  CONTEO=('TYPE','count'),\n",
        "  PROMEDIO_PRICE=('PRICE','mean'),\n",
        "  DESVIACION_PRICE=('PRICE','std'),\n",
        "  PROMEDIO_BEDS=('BEDS','mean'),\n",
        "  DESVIACION_BEDS=('BEDS','std'),\n",
        "  PROMEDIO_BATH=('BATH','mean'),\n",
        "  DESVIACION_BATH=('BATH','std'),\n",
        "  PROMEDIO_PROPERTYSQFT=('PROPERTYSQFT','mean'),\n",
        "  DESVIACION_PROPERTYSQFT=('PROPERTYSQFT','std')\n",
        ").reset_index()\n",
        "\n",
        "#Modelo\n",
        "## Se genera el modelo en python:\n",
        "\n",
        "features = data[[\"TYPE\",\"BEDS\",\"BATH\",\"PROPERTYSQFT\",\"STATE_2\",\"codigo_postal\",\n",
        "\"SUBLOCALITY\",\"LOCALITY\"]]\n",
        "\n",
        "#se convierte en logaritmica la variable price\n",
        "target = np.log(data[\"PRICE\"])\n",
        "\n",
        "#Convertir variables en dummy para el modelo:(las categoricas)\n",
        "data_encoded = pd.get_dummies(features,\n",
        "columns=[\"TYPE\",\"STATE_2\",\"LOCALITY\",\"SUBLOCALITY\",\"codigo_postal\"],\n",
        "drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_encoded,target,\n",
        "test_size=0.20)\n",
        "\n",
        "model=LinearRegression()\n",
        "model.fit(X_train,y_train)\n",
        "predictions=model.predict(X_test)\n",
        "\n",
        "#evaluamos el modelo\n",
        "mean_absolute_error(predictions,y_test)\n",
        "np.sqrt(mean_squared_error(predictions, y_test))\n",
        "\n",
        "model.score(X_test,y_test)\n",
        "model.coef_\n"
      ]
    }
  ]
}